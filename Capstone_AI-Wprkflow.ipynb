{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion made as a script to automate the process.\n",
    "### Provide the data path with single or multiple json files and it will load and combine the \n",
    "### Files in single Python DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def ingest_stream_data(file_path):\n",
    "    \"\"\"\n",
    "    load and combine the stream data\n",
    "    \"\"\"\n",
    "    os.chdir(file_path)\n",
    "    \n",
    "    List_Files = os.listdir(file_path)\n",
    "    \n",
    "    \n",
    "    df_streams = []\n",
    "    df_temp = []\n",
    "    \n",
    "    for file in List_Files:\n",
    "        \n",
    "        #print(file)\n",
    "        str = file_path + '\\\\' + file\n",
    "        #print(str)\n",
    "                        \n",
    "        df_temp = pd.read_json(str)\n",
    "        df_temp.rename(columns = {'price':'total_price'}, inplace = True)\n",
    "        df_temp.rename(columns = {'TimesViewed':'times_viewed'}, inplace = True)\n",
    "        df_temp.rename(columns = {'StreamID':'stream_id'}, inplace = True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(df_temp)\n",
    "        \n",
    "        df_streams.append(df_temp)\n",
    "                  \n",
    "    \n",
    "    df_streams = pd.concat(df_streams, sort=True)\n",
    "        \n",
    "    print(df_streams)\n",
    "    \n",
    "    df_streams['stream_id'] = df_streams['stream_id'].str.extract(r'(\\d+)', expand=False)\n",
    "    df_streams['stream_id'].astype(int)\n",
    "    return(df_streams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = ingest_stream_data('C:\\\\Nilabja\\\\Supportive Docs and Material\\\\Badge and Training\\\\AI Workflow Specialization\\\\capctone\\\\ai-workflow-capstone-master\\\\ai-workflow-capstone-master\\\\cs-train')\n",
    "os.chdir('C:\\\\Nilabja\\\\Supportive Docs and Material\\\\Badge and Training\\\\AI Workflow Specialization\\\\capctone\\\\ai-workflow-capstone-master\\\\ai-workflow-capstone-master')\n",
    "\n",
    "df_main.to_csv('file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.describe()\n",
    "df_main.isnull().sum()\n",
    "df_main.info()\n",
    "df_rev = df_main.groupby('country')['total_price'].sum().reset_index()\n",
    "df_rev = df_rev.sort_values(by=['total_price'], ascending= False)\n",
    "print(df_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reorder=df_main[['country', 'customer_id', 'invoice', 'total_price', 'stream_id', 'times_viewed', 'year', 'month', 'day']]\n",
    "df_reorder "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
